'''
script to replace all entity texts with entityIDs
feature vector:
[
shortest dependency path - raw
  shortest dependency path - POS
  distance to main verb/root
]

@author Peace Han
'''
import regex as re
import xml.etree.ElementTree as ET


def replace_ent(abstract):
    pattern = "<entity.*?<\/entity>"
    abstractList = re.split(pattern, abstract)
    # print(abstractList)

    # print("entities:")
    res = re.findall(pattern, abstract)
    # [print(x) for x in res]
    pattern2 = '<entity id="(.*?)">'
    pattern3 = '<entity.*?>(.*?)</entity>'
    ents = []  # list of all entities occurring in this abstract
    for ent in res:
        id = re.match(pattern2, ent).group(1)
        t = re.match(pattern3, ent).group(1)
        # print(id, t)
        # entities are tuples of id, text
        ents.append((id, t))
        # p.write(id + ',')
        # p.write(t + '\n')
    # entCount += len(res)
    # print(ents)

    scrubbed = []
    for i in range(len(abstractList)):
        # print(abstractList[i])
        scrubbed.append(abstractList[i].strip())
        if i < len(res):
            # print(re.match(pattern2, res[i]).group(1))
            id = re.match(pattern2, res[i]).group(1)
            scrubbed.append(id)
    scrubbed = ' '.join(scrubbed)
    scrubbed = re.match('<abstract>(.*)</abstract>', scrubbed).group(1)
    scrubbed = scrubbed.strip()
    # print("Original abstract : ", abstract)
    # print("Processed abstract: ", scrubbed)
    # print('-----------------------------------------------')
    return scrubbed, ents


J87_3001 = "PROCESSING DICTIONARY DEFINITIONS WITH PHRASAL PATTERN HIERARCHIES"
J87_3001_abs = '<abstract> This paper shows how <entity id="J87-3001.1">dictionary word sense definitions</entity> can be analysed by applying a hierarchy of <entity id="J87-3001.2">phrasal patterns</entity>. An experimental system embodying this mechanism has been implemented for processing <entity id="J87-3001.3">definitions</entity> from the <entity id="J87-3001.4">Longman Dictionary of Contemporary English</entity>. A property of this <entity id="J87-3001.5">dictionary</entity>, exploited by the system, is that it uses a <entity id="J87-3001.6"> restricted vocabulary </entity> in its <entity id="J87-3001.7">word sense definitions</entity>. The structures generated by the experimental system are intended to be used for the <entity id="J87-3001.8">classification</entity> of new <entity id="J87-3001.9">word senses </entity> in terms of the <entity id="J87-3001.10">senses</entity> of <entity id="J87-3001.11">words</entity> in the <entity id="J87-3001.12">restricted vocabulary</entity>. Examples illustrating the output generated are presented, and some qualitative performance results and problems that were encountered are discussed. The analysis process applies successively more specific <entity id="J87-3001.13">phrasal analysis rules</entity> as determined by a hierarchy of <entity id="J87-3001.14">patterns</entity> in which less specific <entity id="J87-3001.15">patterns </entity> dominate more specific ones. This ensures that reasonable incomplete analyses of the <entity id="J87-3001.16">definitions </entity> are produced when more complete analyses are not possible, resulting in a relatively robust <entity id="J87-3001.17">analysis mechanism</entity>. Thus the work reported addresses two <entity id="J87-3001.18">robustness problems </entity> faced by current experimental <entity id="J87-3001.19">natural language processing systems</entity>: coping with an incomplete <entity id="J87-3001.20">lexicon</entity> and with incomplete <entity id="J87-3001.21">knowledge </entity> of <entity id="J87-3001.22">phrasal constructions</entity>. </abstract>'
I05_5009 = "Evaluating Contextual Dependency of Paraphrases using a Latent Variable Model"
I05_5009_abs = '<abstract> This paper presents an <entity id="I05-5009.1">evaluation method</entity> employing a <entity id="I05-5009.2">latent variable model </entity> for <entity id="I05-5009.3">paraphrases</entity> with their <entity id="I05-5009.4">contexts</entity>. We assume that the <entity id="I05-5009.5">context</entity> of a <entity id="I05-5009.6">sentence</entity> is indicated by a <entity id="I05-5009.7">latent variable</entity> of the <entity id="I05-5009.8">model </entity> as a <entity id="I05-5009.9">topic</entity> and that the <entity id="I05-5009.10">likelihood</entity> of each <entity id="I05-5009.11">variable</entity> can be inferred. A <entity id="I05-5009.12">paraphrase </entity> is evaluated for whether its <entity id="I05-5009.13">sentences</entity> are used in the same <entity id="I05-5009.14">context</entity>. Experimental results showed that the proposed method achieves almost 60% <entity id="I05-5009.15">accuracy</entity> and that there is not a large performance difference between the two <entity id="I05-5009.16">models</entity>. The results also revealed an upper bound of <entity id="I05-5009.17">accuracy </entity> of 77% with the <entity id="I05-5009.18">method</entity> when using only <entity id="I05-5009.19"> topic information</entity>. </abstract>'
P83_1003 = "Crossed Serial Dependencies : A low-power parseable extension to GPSG"
P83_1003_abs = '<abstract> An extension to the <entity id="P83-1003.1">GPSG grammatical formalism</entity> is proposed, allowing <entity id="P83-1003.2">non-terminals </entity> to consist of finite sequences of <entity id="P83-1003.3">category labels</entity>, and allowing <entity id="P83-1003.4">schematic variables </entity> to range over such sequences. The extension is shown to be sufficient to provide a strongly adequate <entity id="P83-1003.5">grammar </entity> for <entity id="P83-1003.6">crossed serial dependencies</entity>, as found in e.g. <entity id="P83-1003.7">Dutch subordinate clauses</entity>. The structures induced for such <entity id="P83-1003.8">constructions </entity> are argued to be more appropriate to data involving <entity id="P83-1003.9">conjunction</entity> than some previous proposals have been. The extension is shown to be parseable by a simple extension to an existing <entity id="P83-1003.10">parsing method</entity> for <entity id="P83-1003.11">GPSG</entity>. </abstract>'


def main():
    print(replace_ent(J87_3001_abs))
    print(replace_ent(I05_5009_abs))
    print(replace_ent(P83_1003_abs))


if __name__ == '__main__':
    main()


'''
path = 'clean/train_data/'
file = path + '1.1.text.xml'
outfile = path + '/1.1.text_abs.txt'
entfile = path + '/1.1.text_ents.csv'
o = open(outfile, 'w')
p = open(entfile, 'w')

tree = ET.parse(file)
root = tree.getroot()
print(root)
print(root.tag)

textCount = 0
entCount = 0
for text in root.findall('text'):
    textCount += 1
    # print(text.find('abstract'))
    abstract = text.find('abstract')
    abstractString = ET.tostring(text.find('abstract'))
    abstractString = abstractString.decode('UTF-8').strip()
    abstractString = ' '.join(abstractString.split('\n'))
    abstractString = ' '.join(re.split('  +', abstractString))
    # [x.strip() for x in abstractString]
    print("Original abstract: \n\t", abstractString)

    pattern = "<entity.*?<\/entity>"
    abstractList = re.split(pattern, abstractString)
    print(abstractList)

    print("entities:")
    res = re.findall(pattern, abstractString)
    # [print(x) for x in res]
    pattern2 = '<entity id="(.*?)">'
    pattern3 = '<entity.*?>(.*?)</entity>'
    for ent in res:
        id = re.match(pattern2, ent).group(1)
        t = re.match(pattern3, ent).group(1)
        # print(id, t)
        # p.write(id + ',')
        # p.write(t + '\n')
    entCount += len(res)

    scrubbed = []
    for i in range(len(abstractList)):
        # print(abstractList[i])
        scrubbed.append(abstractList[i].strip())
        if i < len(res):
            # print(re.match(pattern2, res[i]).group(1))
            id = re.match(pattern2, res[i]).group(1)
            scrubbed.append(id)
    scrubbed = ' '.join(scrubbed)
    scrubbed = re.match('<abstract>(.*)</abstract>', scrubbed).group(1)
    scrubbed = scrubbed.strip()
    print(scrubbed)
    # o.write(scrubbed + '\n')

# o.close()

print("total texts: ", textCount)
print("total entities: ", entCount)

'''

