"""
This is a script to assign one sentence for each pair of entity
in an abstract
feature vector:
[
shortest dependency path - raw
  shortest dependency path - POS
  distance to main verb/root
]

@author Peace Han
"""
import regex as re
import xml.etree.ElementTree as ET
import replaceEntities
from stanfordcorenlp import StanfordCoreNLP


nlp = StanfordCoreNLP(r'/home/peace/CoreNLP/stanford-corenlp-full-2018-10-05/')
"""
This is a class to store text id, title, and original abstract for each document
"""
class Text:
    def __init__(self, text_id, text_title, text_abstract, text_entities):
        self.id = text_id
        self.title = text_title
        self.abstract = text_abstract
        self.sents = split_sents(nlp, text_abstract)
        self.entities = text_entities
        print("Created Text object {}: {}".format(self.id, self.title))
        print("\t" + self.abstract)
        print(self.sents)
        print(self.entities)


def split_sents(nlp, abstract_string):
    # this function takes an nlp object and a full abstract string
    # return: list of sentences
    # sentences are lists of tokens
    sents_list = []  # final list to return
    properties = {'annotators': 'ssplit', 'outputFormat': 'xml'}
    # this actually does the splitting, returns a string in xml format
    ann = nlp.annotate(abstract_string, properties=properties)
    # from the xml string, reconstruct each sentence
    root = ET.fromstring(ann)
    sents_tree = root[0][0]
    for sent in sents_tree:
        out_sent = []
        for tok in sent[0]:
            out_sent.append(tok[0].text)
        sents_list.append(out_sent)
    return sents_list


# test = 'This paper shows how J87-3001.1 can be analysed by applying a hierarchy of J87-3001.2 . An experimental system embodying this mechanism has been implemented for processing J87-3001.3 from the J87-3001.4 . A property of this J87-3001.5 , exploited by the system, is that it uses a J87-3001.6 in its J87-3001.7 . The structures generated by the experimental system are intended to be used for the J87-3001.8 of new J87-3001.9 in terms of the J87-3001.10 of J87-3001.11 in the J87-3001.12 . Examples illustrating the output generated are presented, and some qualitative performance results and problems that were encountered are discussed. The analysis process applies successively more specific J87-3001.13 as determined by a hierarchy of J87-3001.14 in which less specific J87-3001.15 dominate more specific ones. This ensures that reasonable incomplete analyses of the J87-3001.16 are produced when more complete analyses are not possible, resulting in a relatively robust J87-3001.17 . Thus the work reported addresses two J87-3001.18 faced by current experimental J87-3001.19 : coping with an incomplete J87-3001.20 and with incomplete J87-3001.21 of J87-3001.22 .'
# print(split_sents(nlp, test))


path = 'clean/train_data/'
file = path + '1.1.text.xml'
# outfile = path + '/1.1.text_abs.txt'
# entfile = path + '/1.1.text_ents.csv'
# o = open(outfile, 'w')
# p = open(entfile, 'w')


tree = ET.parse(file)
root = tree.getroot()
print(root)
print(root.tag)

textCount = 0
entCount = 0
js = ''

for text in root.findall('text'):
    textCount += 1
    attr = text.attrib
    textId = attr.get('id')
    # print(attr)
    # print(text.find('abstract'))
    title = text.find('title').text.strip()
    abstract = text.find('abstract')
    abstractString = ET.tostring(text.find('abstract'))
    abstractString = abstractString.decode('UTF-8').strip()
    abstractString = ' '.join(abstractString.split('\n'))
    abstractString = ' '.join(re.split('  +', abstractString))
    # [x.strip() for x in abstractString]
    # print("Original abstract: \n\t", abstractString)
    abstractString, entities = replaceEntities.replace_ent(abstractString)
    # js = nlp.annotate(abstractString)
    t = Text(textId, title, abstractString, entities)
    # sents = split_sents(nlp, abstractString)


nlp.close()

# TODO: assign a sentence to each relation in 1.1.relations.txt

